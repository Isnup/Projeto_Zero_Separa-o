{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isnup/Projeto_Zero_Separa-o/blob/main/tflite_custom_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnkJfHtNTLly",
        "outputId": "19c7ec64-8a00-435c-d23d-ab77f6107a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!./Miniconda3-py39_23.3.1-0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda\n"
      ],
      "metadata": {
        "id": "i7Lps10tUN6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f101a36-972a-4b44-9691-924c7a0c2463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-17 11:11:20--  https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70605094 (67M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py39_23. 100%[===================>]  67.33M   224MB/s    in 0.3s    \n",
            "\n",
            "2024-07-17 11:11:20 (224 MB/s) - ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh’ saved [70605094/70605094]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "                                                                                  \n",
            "Installing base environment...\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=24.5.0\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    brotli-python-1.0.9        |   py39h6a678d5_8         359 KB\n",
            "    ca-certificates-2024.7.2   |       h06a4308_0         127 KB\n",
            "    certifi-2024.7.4           |   py39h06a4308_0         158 KB\n",
            "    cffi-1.16.0                |   py39h5eee18b_1         251 KB\n",
            "    conda-package-handling-2.3.0|   py39h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py39h06a4308_0          27 KB\n",
            "    cryptography-42.0.5        |   py39hdda0065_1         2.1 MB\n",
            "    idna-3.7                   |   py39h06a4308_0         113 KB\n",
            "    jsonpatch-1.33             |   py39h06a4308_1          31 KB\n",
            "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
            "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
            "    openssl-3.0.14             |       h5eee18b_0         5.2 MB\n",
            "    packaging-24.1             |   py39h06a4308_0         147 KB\n",
            "    pycosat-0.6.6              |   py39h5eee18b_1          93 KB\n",
            "    pyopenssl-24.0.0           |   py39h06a4308_0          98 KB\n",
            "    python-3.9.19              |       h955ad1f_1        25.1 MB\n",
            "    requests-2.32.2            |   py39h06a4308_0         101 KB\n",
            "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    tqdm-4.66.4                |   py39h2f386ee_0         133 KB\n",
            "    tzdata-2024a               |       h04d1e81_0         116 KB\n",
            "    urllib3-2.2.2              |   py39h06a4308_0         177 KB\n",
            "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    zstandard-0.22.0           |   py39h2c38b39_0         427 KB\n",
            "    zstd-1.5.5                 |       hc292b87_2         643 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        41.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py39h6a678d5_8 \n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_2 \n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  brotlipy-0.7.0-py39h27cfd23_1003\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                     2023.01.10-h06a4308_0 --> 2024.7.2-h06a4308_0 \n",
            "  certifi                          2022.12.7-py39h06a4308_0 --> 2024.7.4-py39h06a4308_0 \n",
            "  cffi                                1.15.1-py39h5eee18b_3 --> 1.16.0-py39h5eee18b_1 \n",
            "  conda-package-han~                   2.0.2-py39h06a4308_0 --> 2.3.0-py39h06a4308_0 \n",
            "  conda-package-str~                   0.7.0-py39h06a4308_0 --> 0.10.0-py39h06a4308_0 \n",
            "  cryptography                        39.0.1-py39h9ce1e76_0 --> 42.0.5-py39hdda0065_1 \n",
            "  idna                                   3.4-py39h06a4308_0 --> 3.7-py39h06a4308_0 \n",
            "  jsonpatch          pkgs/main/noarch::jsonpatch-1.32-pyhd~ --> pkgs/main/linux-64::jsonpatch-1.33-py39h06a4308_1 \n",
            "  libffi                                   3.4.2-h6a678d5_6 --> 3.4.4-h6a678d5_1 \n",
            "  openssl                                 1.1.1t-h7f8727e_0 --> 3.0.14-h5eee18b_0 \n",
            "  packaging                             23.0-py39h06a4308_0 --> 24.1-py39h06a4308_0 \n",
            "  pycosat                              0.6.4-py39h5eee18b_0 --> 0.6.6-py39h5eee18b_1 \n",
            "  pyopenssl                           23.0.0-py39h06a4308_0 --> 24.0.0-py39h06a4308_0 \n",
            "  python                                  3.9.16-h7a1cb2a_2 --> 3.9.19-h955ad1f_1 \n",
            "  requests                            2.28.1-py39h06a4308_1 --> 2.32.2-py39h06a4308_0 \n",
            "  sqlite                                  3.41.1-h5eee18b_0 --> 3.45.3-h5eee18b_0 \n",
            "  tk                                      8.6.12-h1ccaba5_0 --> 8.6.14-h39e8969_0 \n",
            "  tqdm                                4.65.0-py39hb070fc8_0 --> 4.66.4-py39h2f386ee_0 \n",
            "  tzdata                                   2023c-h04d1e81_0 --> 2024a-h04d1e81_0 \n",
            "  urllib3                            1.26.15-py39h06a4308_0 --> 2.2.2-py39h06a4308_0 \n",
            "  xz                                      5.2.10-h5eee18b_1 --> 5.4.6-h5eee18b_1 \n",
            "  zlib                                    1.2.13-h5eee18b_0 --> 1.2.13-h5eee18b_1 \n",
            "  zstandard                           0.19.0-py39h5eee18b_0 --> 0.22.0-py39h2c38b39_0 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "python-3.9.19        | 25.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "tqdm-4.66.4          | 133 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "tk-8.6.14            | 3.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.7.4     | 158 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 111 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.14       | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jsonpatch-1.33       | 31 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-42.0.5  | 2.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 127 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.5           | 643 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pyopenssl-24.0.0     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.2      | 101 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :   0% 0.0006225909938929538/1 [00:00<03:03, 183.81s/it]\n",
            "\n",
            "tk-8.6.14            | 3.4 MB    | :   0% 0.004570887819074975/1 [00:00<00:26, 26.37s/it]\u001b[A\u001b[A\n",
            "tqdm-4.66.4          | 133 KB    | :  12% 0.12028043901185625/1 [00:00<00:00,  1.02s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.7.4     | 158 KB    | :  10% 0.10106031914434281/1 [00:00<00:01,  1.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | :   9% 0.09037653210948446/1 [00:00<00:01,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 111 KB    | :  14% 0.1443625982448102/1 [00:00<00:01,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :   7% 0.0728431462854756/1 [00:00<00:02,  2.48s/it]    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jsonpatch-1.33       | 31 KB     | :  52% 0.5180711462450592/1 [00:00<00:00,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tk-8.6.14            | 3.4 MB    | :  37% 0.370241913345073/1 [00:00<00:00,  1.98it/s]   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-42.0.5  | 2.1 MB    | :   1% 0.007544132530664154/1 [00:00<00:27, 28.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 127 KB    | :  13% 0.12647440251960723/1 [00:00<00:01,  1.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  14% 0.1363474276625569/1 [00:00<00:01,  1.98s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.14       | 5.2 MB    | :  31% 0.31265959266117804/1 [00:00<00:00,  1.27it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tk-8.6.14            | 3.4 MB    | :  85% 0.8456142465288705/1 [00:00<00:00,  3.17it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-42.0.5  | 2.1 MB    | :  82% 0.8223104458423929/1 [00:00<00:00,  3.30it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pyopenssl-24.0.0     | 98 KB     | :  16% 0.1630768005733169/1 [00:00<00:01,  1.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | :   4% 0.044590078272134466/1 [00:00<00:07,  8.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | :   1% 0.012744531418334731/1 [00:00<00:28, 28.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | :  17% 0.17122672073239553/1 [00:00<00:01,  2.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  22% 0.22413275780146338/1 [00:00<00:01,  1.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.14       | 5.2 MB    | :  65% 0.6523762654564965/1 [00:00<00:00,  2.05it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | :  10% 0.10272422332988496/1 [00:00<00:03,  3.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tqdm-4.66.4          | 133 KB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]                \u001b[A\n",
            "tqdm-4.66.4          | 133 KB    | : 100% 1.0/1 [00:00<00:00,  2.35it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | :   2% 0.02486413806395413/1 [00:00<00:17, 17.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  30% 0.3038244050197615/1 [00:00<00:00,  1.43s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.14       | 5.2 MB    | :  95% 0.9530104891691676/1 [00:00<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.7.4     | 158 KB    | : 100% 1.0/1 [00:00<00:00,  1.98it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  42% 0.4239844668411016/1 [00:00<00:00,  1.15s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | : 100% 1.0/1 [00:00<00:00,  1.63it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | : 100% 1.0/1 [00:00<00:00,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 111 KB    | : 100% 1.0/1 [00:00<00:00,  1.51it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  54% 0.5447671196563346/1 [00:00<00:00,  1.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jsonpatch-1.33       | 31 KB     | : 100% 1.0/1 [00:00<00:00,  1.28it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jsonpatch-1.33       | 31 KB     | : 100% 1.0/1 [00:00<00:00,  1.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2024 | 127 KB    | : 100% 1.0/1 [00:00<00:00,  1.42it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  67% 0.6667949544593536/1 [00:00<00:00,  1.05it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.5           | 643 KB    | : 100% 1.0/1 [00:00<00:00,  1.33it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.5           | 643 KB    | : 100% 1.0/1 [00:00<00:00,  1.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pyopenssl-24.0.0     | 98 KB     | : 100% 1.0/1 [00:00<00:00,  1.22it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  79% 0.7900679712501585/1 [00:00<00:00,  1.11it/s]\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | : 100% 1.0/1 [00:00<00:00,  1.00it/s]                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  91% 0.9052473051203549/1 [00:01<00:00,  1.12it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cryptography-42.0.5  | 2.1 MB    | : 100% 1.0/1 [00:01<00:00,  3.30it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | : 100% 1.0/1 [00:01<00:00,  1.19s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | : 100% 1.0/1 [00:01<00:00,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:01<00:00,  1.26s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:01<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.2      | 101 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.2      | 101 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tk-8.6.14            | 3.4 MB    | : 100% 1.0/1 [00:01<00:00,  3.17it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.35s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | : 100% 1.0/1 [00:02<00:00,  1.12it/s]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages')\n"
      ],
      "metadata": {
        "id": "prxmhX6lU_hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n myenv python=3.9\n"
      ],
      "metadata": {
        "id": "tyTJX0t4VEnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b7b9d9-af63-4150-9fa4-49f8760a2143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=24.5.0\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pip-24.0                   |   py39h06a4308_0         2.6 MB\n",
            "    setuptools-69.5.1          |   py39h06a4308_0        1003 KB\n",
            "    wheel-0.43.0               |   py39h06a4308_0         109 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         3.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.7.2-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.14-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.0-py39h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.9.19-h955ad1f_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-69.5.1-py39h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.43.0-py39h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "setuptools-69.5.1    | 1003 KB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "wheel-0.43.0         | 109 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "setuptools-69.5.1    | 1003 KB   | :  34% 0.33514805625933297/1 [00:00<00:00,  3.29it/s]\n",
            "\n",
            "pip-24.0             | 2.6 MB    | :  16% 0.15523536350673095/1 [00:00<00:00,  1.52it/s]\u001b[A\u001b[A\n",
            "wheel-0.43.0         | 109 KB    | : 100% 1.0/1 [00:00<00:00,  5.97it/s]\u001b[A\n",
            "setuptools-69.5.1    | 1003 KB   | : 100% 1.0/1 [00:00<00:00,  1.66it/s]\n",
            "\n",
            "pip-24.0             | 2.6 MB    | : 100% 1.0/1 [00:00<00:00,  1.34it/s]                \u001b[A\u001b[A\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install tflite-model-maker\n"
      ],
      "metadata": {
        "id": "1i-ginSmVN9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693c8fcd-9851-46ca-d273-d11784e00955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting tf-models-official==2.3.0 (from tflite-model-maker)\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting numpy<1.23.4,>=1.17.3 (from tflite-model-maker)\n",
            "  Downloading numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pillow>=7.0.0 (from tflite-model-maker)\n",
            "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting sentencepiece>=0.1.91 (from tflite-model-maker)\n",
            "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tensorflow-datasets>=2.1.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting fire>=0.3.1 (from tflite-model-maker)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatbuffers>=2.0 (from tflite-model-maker)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting absl-py>=0.10.0 (from tflite-model-maker)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from tflite-model-maker)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tflite-support>=0.4.2 (from tflite-model-maker)\n",
            "  Downloading tflite_support-0.4.4-cp39-cp39-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0 (from tflite-model-maker)\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tensorflow>=2.6.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow-2.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting numba>=0.53 (from tflite-model-maker)\n",
            "  Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting librosa==0.8.1 (from tflite-model-maker)\n",
            "  Downloading librosa-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting lxml>=4.6.1 (from tflite-model-maker)\n",
            "  Downloading lxml-5.2.2-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting PyYAML>=5.1 (from tflite-model-maker)\n",
            "  Downloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting matplotlib<3.5.0,>=3.0.3 (from tflite-model-maker)\n",
            "  Downloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting six>=1.12.0 (from tflite-model-maker)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-addons>=0.11.2 (from tflite-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting neural-structured-learning>=1.3.1 (from tflite-model-maker)\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow-model-optimization>=0.5 (from tflite-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting Cython>=0.29.13 (from tflite-model-maker)\n",
            "  Downloading Cython-3.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting scann==1.2.6 (from tflite-model-maker)\n",
            "  Downloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tensorflow-hub<0.13,>=0.7.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting audioread>=2.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting scipy>=1.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting joblib>=0.14 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting decorator>=3.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting soundfile>=0.10.2 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
            "Collecting pooch>=1.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting packaging>=20.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting tensorflow>=2.6.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting dataclasses (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gin-config (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-api-python-client>=1.6.7 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_api_python_client-2.137.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-cloud-bigquery>=0.31.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting kaggle>=1.3.9 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading kaggle-1.6.14.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python-headless (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pandas>=0.22.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting psutil>=5.4.3 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting py-cpuinfo>=3.3.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting tf-slim>=1.1.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting termcolor (from fire>=0.3.1->tflite-model-maker)\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting pyparsing>=2.2.1 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting attrs (from neural-structured-learning>=1.3.1->tflite-model-maker)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.53->tflite-model-maker)\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting gast>=0.2.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting libclang>=9.0.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.9/site-packages (from tensorflow>=2.6.0->tflite-model-maker) (69.5.1)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading grpcio-1.64.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.11.2->tflite-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting array-record (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
            "Collecting click (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting dm-tree (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting promise (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-datasets>=2.1.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading tensorflow_datasets-4.9.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting requests>=2.19.0 (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting toml (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tqdm (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.10.0 (from tflite-model-maker)\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting packaging>=20.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting sounddevice>=0.4.4 (from tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pybind11>=2.6.0 (from tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.43.0)\n",
            "Collecting fsspec (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting importlib_resources (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting zipp (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting certifi>=2023.7.22 (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting python-slugify (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting bleach (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.0->librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Collecting werkzeug>=0.11.15 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting webencodings (from bleach->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tflite_model_maker-0.4.3-py3-none-any.whl (580 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.1/580.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-3.0.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading lxml-5.2.2-cp39-cp39-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m738.9/738.9 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite_support-0.4.4-cp39-cp39-manylinux2014_x86_64.whl (60.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_api_python_client-2.137.0-py2.py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.64.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.5-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.8/238.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-1.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.4/443.4 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.3/142.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
            "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
            "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
            "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire, kaggle, promise\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=14a6495e2adb581c30cbdbde3e1fa5172b796b6b2ff7a15e2a603c047529e71e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/ce/ba/9d5764d2266c500c18776c7d8f1e3c023075994cbc6dea47db\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.6.14-py3-none-any.whl size=105119 sha256=ea414545785a7165eb5ad958b2d9dba06207885f6e59f40f6363b05c3f887d50\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/f1/ec/3f9079ada5cc1218f9accf05ccca9f0a57533191e49d76e3f6\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=4730cf2a34c150871eb94354b2461bbe9d193b79a7ec45b0ab24031e5a19e115\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "Successfully built fire kaggle promise\n",
            "Installing collected packages: webencodings, text-unidecode, tensorflow-estimator, tensorboard-plugin-wit, sentencepiece, pytz, py-cpuinfo, libclang, keras, gin-config, flatbuffers, dm-tree, dataclasses, zipp, wrapt, urllib3, uritemplate, tzdata, typing-extensions, typeguard, tqdm, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, PyYAML, python-slugify, pyparsing, pycparser, pybind11, pyasn1, psutil, protobuf, platformdirs, pillow, oauthlib, numpy, MarkupSafe, lxml, llvmlite, kiwisolver, joblib, idna, grpcio, google-crc32c, gast, fsspec, etils, decorator, Cython, cycler, click, charset-normalizer, certifi, cachetools, audioread, attrs, absl-py, werkzeug, tf-slim, tensorflow-model-optimization, tensorflow-hub, scipy, rsa, requests, python-dateutil, pyasn1-modules, proto-plus, promise, packaging, opt-einsum, opencv-python-headless, numba, keras-preprocessing, importlib_resources, importlib-metadata, httplib2, h5py, googleapis-common-protos, google-resumable-media, google-pasta, fire, CFFI, bleach, astunparse, tensorflow-metadata, tensorflow-addons, soundfile, sounddevice, scikit-learn, resampy, requests-oauthlib, pooch, pandas, neural-structured-learning, matplotlib, markdown, kaggle, grpcio-status, google-auth, tflite-support, librosa, google-auth-oauthlib, google-auth-httplib2, google-api-core, array-record, tensorflow-datasets, tensorboard, google-cloud-core, google-api-python-client, tensorflow, google-cloud-bigquery, tf-models-official, tensorflowjs, scann, tflite-model-maker\n",
            "Successfully installed CFFI-1.16.0 Cython-3.0.10 MarkupSafe-2.1.5 PyYAML-6.0.1 absl-py-1.4.0 array-record-0.5.1 astunparse-1.6.3 attrs-23.2.0 audioread-3.0.1 bleach-6.1.0 cachetools-5.4.0 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 cycler-0.12.1 dataclasses-0.6 decorator-5.1.1 dm-tree-0.1.8 etils-1.5.2 fire-0.6.0 flatbuffers-24.3.25 fsspec-2024.6.1 gast-0.6.0 gin-config-0.5.0 google-api-core-2.19.1 google-api-python-client-2.137.0 google-auth-2.32.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-0.4.6 google-cloud-bigquery-3.25.0 google-cloud-core-2.4.1 google-crc32c-1.5.0 google-pasta-0.2.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.1 grpcio-1.64.1 grpcio-status-1.48.2 h5py-3.11.0 httplib2-0.22.0 idna-3.7 importlib-metadata-8.0.0 importlib_resources-6.4.0 joblib-1.4.2 kaggle-1.6.14 keras-2.8.0 keras-preprocessing-1.1.2 kiwisolver-1.4.5 libclang-18.1.1 librosa-0.8.1 llvmlite-0.43.0 lxml-5.2.2 markdown-3.6 matplotlib-3.4.3 neural-structured-learning-1.4.0 numba-0.60.0 numpy-1.23.3 oauthlib-3.2.2 opencv-python-headless-4.10.0.84 opt-einsum-3.3.0 packaging-20.9 pandas-2.2.2 pillow-10.4.0 platformdirs-4.2.2 pooch-1.8.2 promise-2.3 proto-plus-1.24.0 protobuf-3.19.6 psutil-6.0.0 py-cpuinfo-9.0.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pybind11-2.13.1 pycparser-2.22 pyparsing-3.1.2 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2024.1 requests-2.32.3 requests-oauthlib-2.0.0 resampy-0.4.3 rsa-4.9 scann-1.2.6 scikit-learn-1.5.1 scipy-1.13.1 sentencepiece-0.2.0 six-1.16.0 sounddevice-0.4.7 soundfile-0.12.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.0 tensorflow-estimator-2.8.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-metadata-1.13.0 tensorflow-model-optimization-0.8.0 tensorflowjs-3.18.0 termcolor-2.4.0 text-unidecode-1.3 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.3 tflite-support-0.4.4 threadpoolctl-3.5.0 toml-0.10.2 tqdm-4.66.4 typeguard-2.13.3 typing-extensions-4.12.2 tzdata-2024.1 uritemplate-4.1.1 urllib3-1.25.11 webencodings-0.5.1 werkzeug-3.0.3 wrapt-1.16.0 zipp-3.19.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install ipykernel\n"
      ],
      "metadata": {
        "id": "L9x7qiDMVvs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "985a65d4-d598-4f42-93b0-32f1a51851fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel)\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (20.9)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (6.0.0)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-26.0.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel)\n",
            "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Collecting exceptiongroup (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.2.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/envs/myenv/lib/python3.9/site-packages (from packaging->ipykernel) (3.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.19.2)\n",
            "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.2/808.2 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading pyzmq-26.0.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.8/912.8 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.8/436.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, traitlets, tornado, pyzmq, pygments, prompt-toolkit, pexpect, parso, nest-asyncio, executing, exceptiongroup, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, comm, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-2.4.1 comm-0.2.2 debugpy-1.8.2 exceptiongroup-1.2.2 executing-2.0.1 ipykernel-6.29.5 ipython-8.18.1 jedi-0.19.1 jupyter-client-8.6.2 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 parso-0.8.4 pexpect-4.9.0 prompt-toolkit-3.0.47 ptyprocess-0.7.0 pure-eval-0.2.2 pygments-2.18.0 pyzmq-26.0.3 stack-data-0.6.3 tornado-6.4.1 traitlets-5.14.3 wcwidth-0.2.13\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install opencv-python\n",
        "python --version\n"
      ],
      "metadata": {
        "id": "3kplk-ZGV05z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f04e00-a218-4e5c-8827-94aff23a07c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from opencv-python) (1.23.3)\n",
            "Downloading opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.10.0.84\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mPython 3.9.19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install numpy==1.23.4"
      ],
      "metadata": {
        "id": "SOWuHh2tV7Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4773b1-62a0-4a18-94da-b5131e2ec0d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.4\n",
            "  Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.3\n",
            "    Uninstalling numpy-1.23.3:\n",
            "      Successfully uninstalled numpy-1.23.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tflite-model-maker 0.4.3 requires numpy<1.23.4,>=1.17.3, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install pycocotools"
      ],
      "metadata": {
        "id": "01VE11RRV_8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c201749e-a357-41bb-aca6-ee612d9e5526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from pycocotools) (3.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.9/site-packages (from pycocotools) (1.23.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Downloading pycocotools-2.0.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (432 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.9/432.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycocotools\n",
            "Successfully installed pycocotools-2.0.8\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# !ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "# !ls /mydrive\n"
      ],
      "metadata": {
        "id": "iiNoFPUwlRGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/imagens.zip\n"
      ],
      "metadata": {
        "id": "vXcZcfLZbScY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7f1144d1-55a0-4598-d703-ee7b763e3065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/imagens.zip\n",
            "warning:  /content/imagens.zip appears to use backslashes as path separators\n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/100.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/100.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/101.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/101.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/102.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/102.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/103.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/103.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/104.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/104.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/40.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/40.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/41.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/41.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/42.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/42.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/43.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/43.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/44.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/44.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/45.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/45.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/46.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/46.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/50.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/50.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/51.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/51.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/52.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/52.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/53.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/53.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/54.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/54.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/55.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/55.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/56.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/56.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/57.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/57.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/58.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/58.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/61.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/61.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/62.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/62.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/63.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/63.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/64.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/64.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/65.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/65.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/66.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/66.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/67.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/67.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/68.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/68.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/69.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/69.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/71.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/71.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/72.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/72.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/73.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/73.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/74.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/74.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/80.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/80.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/81.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/81.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/82.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/82.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/83.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/83.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/84.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/84.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/85.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/85.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/86.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/86.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/89.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/89.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/90.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/90.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/91.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/91.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/92.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/92.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/93.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/93.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/94.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/94.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/95.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/95.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/99.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/99.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (100).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (100).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (101).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (101).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (102).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (102).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (103).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (103).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (104).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (104).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (105).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (105).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (106).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (106).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (107).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (107).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (108).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (108).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (109).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (109).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (110).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (110).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (111).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (111).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (112).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (112).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (113).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (113).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (22).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (22).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (23).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (23).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (24).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (24).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (25).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (25).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (26).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (26).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (27).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (27).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (28).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (28).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (29).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (29).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (30).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (30).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (32).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (32).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (35).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (35).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (36).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (36).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (37).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (37).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (38).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (38).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (39).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (39).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (40).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (40).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (41).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (41).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (42).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (42).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (43).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (43).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (44).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (44).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (45).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (45).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (46).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (46).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (47).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (47).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (48).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (48).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (49).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (49).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (50).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (50).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (52).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (52).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (53).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (53).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (54).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (54).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (55).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (55).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (56).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (56).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (57).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (57).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (60).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (60).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (61).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (61).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (62).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (62).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (63).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (63).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (64).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (64).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (65).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (65).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (66).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (66).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (67).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (67).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (68).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (68).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (69).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (69).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (70).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (70).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (71).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (71).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (72).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (72).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (73).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (73).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (74).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (74).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (77).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (77).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (78).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (78).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (79).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (79).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (80).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (80).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (81).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (81).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (82).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (82).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (83).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (83).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (84).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (84).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (85).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (85).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (86).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (86).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (87).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (87).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (88).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (88).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (90).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (90).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (91).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (91).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (92).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (92).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (93).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (93).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (94).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (94).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (95).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (95).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (96).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (96).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (97).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (97).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (98).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (98).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (99).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa (99).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/CompleTa.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (1).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (1).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (10).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (10).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (100).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (100).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (101).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (101).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (102).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (102).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (103).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (103).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (104).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (104).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (105).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (105).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (11).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (11).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (12).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (12).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (13).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (13).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (14).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (14).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (15).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (15).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (16).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (16).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (17).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (17).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (18).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (18).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (19).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (19).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (2).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (2).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (20).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (20).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (21).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (21).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (22).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (22).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (23).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (23).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (24).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (24).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (25).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (25).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (26).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (26).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (27).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (27).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (28).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (28).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (29).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (29).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (3).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (3).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (30).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (30).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (31).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (31).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (32).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (32).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (33).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (33).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (34).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (34).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (35).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (35).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (36).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (36).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (37).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (37).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (38).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (38).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (39).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (39).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (4).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (4).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (40).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (40).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (41).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (41).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (42).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (42).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (43).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (43).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (44).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (44).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (45).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (45).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (46).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (46).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (47).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (47).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (48).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (48).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (49).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (49).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (5).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (5).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (50).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (50).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (51).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (51).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (52).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (52).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (53).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (53).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (54).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (54).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (55).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (55).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (56).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (56).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (57).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (57).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (58).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (58).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (59).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (59).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (6).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (6).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (60).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (60).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (61).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (61).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (62).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (62).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (63).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (63).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (64).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (64).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (65).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (65).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (66).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (66).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (67).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (67).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (68).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (68).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (69).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (69).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (7).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (7).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (70).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (70).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (71).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (71).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (72).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (72).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (74).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (74).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (75).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (75).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (76).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (76).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (77).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (77).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (78).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (78).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (79).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (79).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (8).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (8).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (80).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (80).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (81).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (81).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (82).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (82).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (83).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (83).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (84).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (84).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (85).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (85).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (86).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (86).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (87).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (87).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (88).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (88).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (89).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (89).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (9).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (9).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (90).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (90).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (91).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (91).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (92).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (92).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (93).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (93).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (94).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (94).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (95).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (95).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (96).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (96).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (97).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (97).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (98).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (98).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (99).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2 (99).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/incompletas2.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_1.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_1.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_10.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_10.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_100.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_100.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_11.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_11.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_12.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_12.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_13.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_13.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_14.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_14.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_15.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_15.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_16.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_16.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_17.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_17.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_18.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_18.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_19.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_19.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_2.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_2.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_20.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_20.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_21.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_21.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_22.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_22.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_23.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_23.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_24.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_24.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_25.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_25.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_26.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_26.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_27.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_27.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_28.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_28.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_29.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_29.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_3.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_3.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_30.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_30.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_31.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_31.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_32.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_32.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_33.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_33.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_34.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_34.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_38.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_38.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_39.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_39.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_4.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_4.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_40.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_40.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_41.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_41.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_42.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_42.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_43.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_43.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_44.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_44.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_45.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_45.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_46.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_46.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_49.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_49.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_5.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_5.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_50.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_50.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_51.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_51.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_52.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_52.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_53.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_53.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_54.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_54.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_55.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_55.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_56.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_56.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_57.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_57.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_58.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_58.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_59.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_59.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_6.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_6.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_60.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_60.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_61.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_61.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_62.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_62.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_63.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_63.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_64.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_64.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_65.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_65.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_66.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_66.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_67.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_67.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_68.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_68.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_69.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_69.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_7.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_7.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_70.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_70.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_71.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_71.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_72.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_72.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_73.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_73.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_74.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_74.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_75.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_75.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_76.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_76.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_77.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_77.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_78.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_78.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_79.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_79.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_8.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_8.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_80.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_80.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_81.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_81.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_82.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_82.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_83.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_83.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_84.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_84.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_85.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_85.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_86.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_86.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_87.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_87.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_88.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_88.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_9.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_9.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_90.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_90.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_91.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_91.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_92.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_92.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_93.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_93.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_94.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_94.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_95.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_95.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_96.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_96.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_97.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_97.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_98.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_98.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_99.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA COMPLETA_99.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_100.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_100.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_11.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_11.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_12.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_12.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_13.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_13.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_14.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_14.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_15.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_15.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_17.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_17.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_18.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_18.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_19.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_19.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_20.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_20.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_21.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_21.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_23.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_23.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_24.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_24.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_25.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_25.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_27.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_27.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_29.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_29.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_30.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_30.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_31.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_31.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_32.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_32.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_34.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_34.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_37.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_37.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_38.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_38.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_39.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_39.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_40.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_40.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_41.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_41.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_43.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_43.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_44.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_44.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_46.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_46.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_47.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_47.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_48.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_48.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_49.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_49.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_51.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_51.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_52.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_52.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_53.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_53.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_54.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_54.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_59.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_59.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_60.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_60.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_61.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_61.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_62.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_62.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_63.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_63.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_65.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_65.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_66.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_66.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_67.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_67.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_69.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_69.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_70.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_70.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_72.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_72.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_73.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_73.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_74.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_74.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_76.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_76.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_77.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_77.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_78.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_78.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_79.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_79.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_81.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_81.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_82.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_82.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_83.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_83.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_84.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_84.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_85.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_85.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_87.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_87.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_9.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_9.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_90.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_90.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_91.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_91.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_92.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_92.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_93.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_93.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_96.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_96.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_97.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_97.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_99.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/train/REF_CAIXA INCOMPLETA_99.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/0.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/0.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/1.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/1.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/10.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/10.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/105.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/105.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/106.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/106.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/107.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/107.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/108.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/108.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/112.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/112.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/113.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/113.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/114.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/114.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/115.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/115.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/116.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/116.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/117.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/117.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/118.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/118.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/119.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/119.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/12.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/12.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/120.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/120.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/121.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/121.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/123.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/123.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/124.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/124.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/125.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/125.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/126.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/126.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/127.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/127.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/128.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/128.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/129.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/129.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/13.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/13.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/130.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/130.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/14.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/14.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/15.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/15.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/16.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/16.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/17.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/17.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/18.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/18.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/19.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/19.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/2.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/2.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/20.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/20.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/25.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/25.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/26.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/26.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/27.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/27.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/28.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/28.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/29.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/29.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/3.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/3.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/30.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/30.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/31.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/31.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/32.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/32.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/33.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/33.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/36.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/36.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/37.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/37.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/38.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/38.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/39.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/39.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/5.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/5.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/6.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/6.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/7.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/7.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/8.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/8.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/9.jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/9.xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (1).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (1).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (10).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (10).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (11).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (11).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (12).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (12).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (13).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (13).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (14).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (14).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (15).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (15).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (16).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (16).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (17).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (17).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (18).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (18).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (19).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (19).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (2).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (2).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (3).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (3).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (4).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (4).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (5).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (5).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (6).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (6).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (7).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (7).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (8).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (8).xml  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (9).jpg  \n",
            "  inflating: IMAGENS TREINAMENTO MACHINE LEARNING/validate/CompleTa (9).xml  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python /content/train.py"
      ],
      "metadata": {
        "id": "PFrWbYq-yt8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c92beb7-5d73-4813-93c2-93a05cb4f6dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-17 11:24:53.728528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-07-17 11:24:53.728570: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "2024-07-17 11:24:58.578975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2024-07-17 11:24:58.579522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-07-17 11:24:58.579810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-07-17 11:24:58.580011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-07-17 11:24:58.580271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-07-17 11:24:59.236909: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-07-17 11:24:59.242582: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-07-17 11:24:59.243227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-17 11:25:11.670457: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "Epoch 1/30\n",
            "2024-07-17 11:25:39.867358: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39321600 exceeds 10% of free system memory.\n",
            "2024-07-17 11:25:39.933043: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 39321600 exceeds 10% of free system memory.\n",
            "2024-07-17 11:25:40.182649: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745600 exceeds 10% of free system memory.\n",
            "2024-07-17 11:25:40.202213: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745600 exceeds 10% of free system memory.\n",
            "2024-07-17 11:25:40.254736: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745600 exceeds 10% of free system memory.\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.9003 - cls_loss: 0.6328 - box_loss: 0.0053 - reg_l2_loss: 0.0630 - loss: 0.9633 - learning_rate: 0.0065 - gradient_norm: 2.89752024-07-17 11:28:58.439628: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 240s 2s/step - det_loss: 0.8953 - cls_loss: 0.6300 - box_loss: 0.0053 - reg_l2_loss: 0.0630 - loss: 0.9583 - learning_rate: 0.0065 - gradient_norm: 2.8860 - val_det_loss: 0.5153 - val_cls_loss: 0.3897 - val_box_loss: 0.0025 - val_reg_l2_loss: 0.0630 - val_loss: 0.5783\n",
            "Epoch 2/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.4324 - cls_loss: 0.3440 - box_loss: 0.0018 - reg_l2_loss: 0.0630 - loss: 0.4954 - learning_rate: 0.0050 - gradient_norm: 2.16462024-07-17 11:32:25.032835: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 200s 2s/step - det_loss: 0.4304 - cls_loss: 0.3425 - box_loss: 0.0018 - reg_l2_loss: 0.0630 - loss: 0.4935 - learning_rate: 0.0050 - gradient_norm: 2.1613 - val_det_loss: 0.2462 - val_cls_loss: 0.1918 - val_box_loss: 0.0011 - val_reg_l2_loss: 0.0630 - val_loss: 0.3093\n",
            "Epoch 3/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.3594 - cls_loss: 0.2970 - box_loss: 0.0012 - reg_l2_loss: 0.0631 - loss: 0.4224 - learning_rate: 0.0049 - gradient_norm: 2.81222024-07-17 11:35:46.033551: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 203s 2s/step - det_loss: 0.3592 - cls_loss: 0.2970 - box_loss: 0.0012 - reg_l2_loss: 0.0631 - loss: 0.4222 - learning_rate: 0.0049 - gradient_norm: 2.8174 - val_det_loss: 0.1959 - val_cls_loss: 0.1481 - val_box_loss: 9.5624e-04 - val_reg_l2_loss: 0.0631 - val_loss: 0.2590\n",
            "Epoch 4/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.3071 - cls_loss: 0.2547 - box_loss: 0.0010 - reg_l2_loss: 0.0631 - loss: 0.3702 - learning_rate: 0.0048 - gradient_norm: 3.21742024-07-17 11:39:09.454048: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 202s 2s/step - det_loss: 0.3061 - cls_loss: 0.2538 - box_loss: 0.0010 - reg_l2_loss: 0.0631 - loss: 0.3692 - learning_rate: 0.0048 - gradient_norm: 3.2020 - val_det_loss: 0.1719 - val_cls_loss: 0.1356 - val_box_loss: 7.2576e-04 - val_reg_l2_loss: 0.0631 - val_loss: 0.2350\n",
            "Epoch 5/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.2675 - cls_loss: 0.2245 - box_loss: 8.6047e-04 - reg_l2_loss: 0.0631 - loss: 0.3306 - learning_rate: 0.0047 - gradient_norm: 3.36002024-07-17 11:42:30.137177: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 214s 2s/step - det_loss: 0.2677 - cls_loss: 0.2247 - box_loss: 8.5900e-04 - reg_l2_loss: 0.0631 - loss: 0.3308 - learning_rate: 0.0047 - gradient_norm: 3.3537 - val_det_loss: 0.1565 - val_cls_loss: 0.1282 - val_box_loss: 5.6555e-04 - val_reg_l2_loss: 0.0632 - val_loss: 0.2196\n",
            "Epoch 6/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.2584 - cls_loss: 0.2146 - box_loss: 8.7563e-04 - reg_l2_loss: 0.0632 - loss: 0.3216 - learning_rate: 0.0046 - gradient_norm: 2.92952024-07-17 11:46:03.176118: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 201s 2s/step - det_loss: 0.2575 - cls_loss: 0.2138 - box_loss: 8.7449e-04 - reg_l2_loss: 0.0632 - loss: 0.3207 - learning_rate: 0.0046 - gradient_norm: 2.9159 - val_det_loss: 0.1814 - val_cls_loss: 0.1571 - val_box_loss: 4.8637e-04 - val_reg_l2_loss: 0.0632 - val_loss: 0.2446\n",
            "Epoch 7/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.2275 - cls_loss: 0.1909 - box_loss: 7.3135e-04 - reg_l2_loss: 0.0632 - loss: 0.2907 - learning_rate: 0.0044 - gradient_norm: 2.92762024-07-17 11:49:21.681722: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 197s 2s/step - det_loss: 0.2268 - cls_loss: 0.1903 - box_loss: 7.3029e-04 - reg_l2_loss: 0.0632 - loss: 0.2900 - learning_rate: 0.0044 - gradient_norm: 2.9148 - val_det_loss: 0.1980 - val_cls_loss: 0.1695 - val_box_loss: 5.6972e-04 - val_reg_l2_loss: 0.0632 - val_loss: 0.2612\n",
            "Epoch 8/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.2139 - cls_loss: 0.1793 - box_loss: 6.9112e-04 - reg_l2_loss: 0.0632 - loss: 0.2771 - learning_rate: 0.0042 - gradient_norm: 3.08502024-07-17 11:52:39.750268: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 198s 2s/step - det_loss: 0.2131 - cls_loss: 0.1786 - box_loss: 6.9102e-04 - reg_l2_loss: 0.0632 - loss: 0.2764 - learning_rate: 0.0042 - gradient_norm: 3.0698 - val_det_loss: 0.3285 - val_cls_loss: 0.3059 - val_box_loss: 4.5118e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.3917\n",
            "Epoch 9/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1943 - cls_loss: 0.1653 - box_loss: 5.7999e-04 - reg_l2_loss: 0.0633 - loss: 0.2575 - learning_rate: 0.0040 - gradient_norm: 2.87192024-07-17 11:55:56.727523: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 199s 2s/step - det_loss: 0.1941 - cls_loss: 0.1651 - box_loss: 5.7871e-04 - reg_l2_loss: 0.0633 - loss: 0.2573 - learning_rate: 0.0040 - gradient_norm: 2.8591 - val_det_loss: 0.2400 - val_cls_loss: 0.2203 - val_box_loss: 3.9265e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.3032\n",
            "Epoch 10/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1926 - cls_loss: 0.1595 - box_loss: 6.6165e-04 - reg_l2_loss: 0.0633 - loss: 0.2559 - learning_rate: 0.0038 - gradient_norm: 2.77692024-07-17 11:59:25.219910: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 217s 2s/step - det_loss: 0.1921 - cls_loss: 0.1590 - box_loss: 6.6263e-04 - reg_l2_loss: 0.0633 - loss: 0.2554 - learning_rate: 0.0038 - gradient_norm: 2.7630 - val_det_loss: 0.3201 - val_cls_loss: 0.2964 - val_box_loss: 4.7344e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.3834\n",
            "Epoch 11/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1726 - cls_loss: 0.1435 - box_loss: 5.8061e-04 - reg_l2_loss: 0.0633 - loss: 0.2359 - learning_rate: 0.0036 - gradient_norm: 2.29612024-07-17 12:03:08.159159: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 218s 2s/step - det_loss: 0.1731 - cls_loss: 0.1439 - box_loss: 5.8397e-04 - reg_l2_loss: 0.0633 - loss: 0.2364 - learning_rate: 0.0035 - gradient_norm: 2.3051 - val_det_loss: 0.1250 - val_cls_loss: 0.1011 - val_box_loss: 4.7692e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1883\n",
            "Epoch 12/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1749 - cls_loss: 0.1490 - box_loss: 5.1879e-04 - reg_l2_loss: 0.0633 - loss: 0.2382 - learning_rate: 0.0033 - gradient_norm: 2.46522024-07-17 12:06:53.138447: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 222s 2s/step - det_loss: 0.1743 - cls_loss: 0.1485 - box_loss: 5.1670e-04 - reg_l2_loss: 0.0633 - loss: 0.2376 - learning_rate: 0.0033 - gradient_norm: 2.4505 - val_det_loss: 0.2171 - val_cls_loss: 0.1958 - val_box_loss: 4.2552e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2804\n",
            "Epoch 13/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1503 - cls_loss: 0.1247 - box_loss: 5.1095e-04 - reg_l2_loss: 0.0633 - loss: 0.2136 - learning_rate: 0.0030 - gradient_norm: 2.38682024-07-17 12:10:28.416382: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 213s 2s/step - det_loss: 0.1511 - cls_loss: 0.1255 - box_loss: 5.1146e-04 - reg_l2_loss: 0.0633 - loss: 0.2144 - learning_rate: 0.0030 - gradient_norm: 2.4630 - val_det_loss: 0.1543 - val_cls_loss: 0.1343 - val_box_loss: 3.9950e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2176\n",
            "Epoch 14/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1511 - cls_loss: 0.1259 - box_loss: 5.0496e-04 - reg_l2_loss: 0.0633 - loss: 0.2144 - learning_rate: 0.0028 - gradient_norm: 2.66002024-07-17 12:14:02.391461: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 214s 2s/step - det_loss: 0.1521 - cls_loss: 0.1268 - box_loss: 5.0564e-04 - reg_l2_loss: 0.0633 - loss: 0.2154 - learning_rate: 0.0028 - gradient_norm: 2.7006 - val_det_loss: 0.1382 - val_cls_loss: 0.1157 - val_box_loss: 4.4863e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2015\n",
            "Epoch 15/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1398 - cls_loss: 0.1133 - box_loss: 5.2902e-04 - reg_l2_loss: 0.0633 - loss: 0.2031 - learning_rate: 0.0025 - gradient_norm: 2.14332024-07-17 12:17:36.546727: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 224s 2s/step - det_loss: 0.1408 - cls_loss: 0.1141 - box_loss: 5.3510e-04 - reg_l2_loss: 0.0633 - loss: 0.2042 - learning_rate: 0.0025 - gradient_norm: 2.1684 - val_det_loss: 0.0956 - val_cls_loss: 0.0797 - val_box_loss: 3.1738e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1589\n",
            "Epoch 16/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1226 - cls_loss: 0.1014 - box_loss: 4.2480e-04 - reg_l2_loss: 0.0633 - loss: 0.1860 - learning_rate: 0.0022 - gradient_norm: 2.11792024-07-17 12:21:26.289100: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 220s 2s/step - det_loss: 0.1224 - cls_loss: 0.1013 - box_loss: 4.2291e-04 - reg_l2_loss: 0.0633 - loss: 0.1857 - learning_rate: 0.0022 - gradient_norm: 2.1135 - val_det_loss: 0.0988 - val_cls_loss: 0.0810 - val_box_loss: 3.5783e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1622\n",
            "Epoch 17/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1337 - cls_loss: 0.1120 - box_loss: 4.3457e-04 - reg_l2_loss: 0.0633 - loss: 0.1971 - learning_rate: 0.0020 - gradient_norm: 2.42902024-07-17 12:25:12.193534: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 229s 2s/step - det_loss: 0.1332 - cls_loss: 0.1116 - box_loss: 4.3225e-04 - reg_l2_loss: 0.0633 - loss: 0.1965 - learning_rate: 0.0020 - gradient_norm: 2.4132 - val_det_loss: 0.1025 - val_cls_loss: 0.0841 - val_box_loss: 3.6840e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1659\n",
            "Epoch 18/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1368 - cls_loss: 0.1136 - box_loss: 4.6400e-04 - reg_l2_loss: 0.0633 - loss: 0.2001 - learning_rate: 0.0017 - gradient_norm: 2.04152024-07-17 12:29:08.517204: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 233s 2s/step - det_loss: 0.1364 - cls_loss: 0.1134 - box_loss: 4.6171e-04 - reg_l2_loss: 0.0633 - loss: 0.1998 - learning_rate: 0.0017 - gradient_norm: 2.0324 - val_det_loss: 0.1154 - val_cls_loss: 0.0987 - val_box_loss: 3.3483e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1787\n",
            "Epoch 19/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1098 - cls_loss: 0.0905 - box_loss: 3.8700e-04 - reg_l2_loss: 0.0633 - loss: 0.1732 - learning_rate: 0.0015 - gradient_norm: 1.54902024-07-17 12:33:11.202766: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 244s 2s/step - det_loss: 0.1096 - cls_loss: 0.0903 - box_loss: 3.8710e-04 - reg_l2_loss: 0.0633 - loss: 0.1730 - learning_rate: 0.0015 - gradient_norm: 1.5450 - val_det_loss: 0.1162 - val_cls_loss: 0.0995 - val_box_loss: 3.3539e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1796\n",
            "Epoch 20/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1264 - cls_loss: 0.1050 - box_loss: 4.2901e-04 - reg_l2_loss: 0.0633 - loss: 0.1898 - learning_rate: 0.0012 - gradient_norm: 2.08002024-07-17 12:36:58.801467: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 238s 2s/step - det_loss: 0.1262 - cls_loss: 0.1048 - box_loss: 4.2848e-04 - reg_l2_loss: 0.0633 - loss: 0.1895 - learning_rate: 0.0012 - gradient_norm: 2.0704 - val_det_loss: 0.1995 - val_cls_loss: 0.1819 - val_box_loss: 3.5134e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2628\n",
            "Epoch 21/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1089 - cls_loss: 0.0901 - box_loss: 3.7591e-04 - reg_l2_loss: 0.0633 - loss: 0.1722 - learning_rate: 9.8889e-04 - gradient_norm: 1.66552024-07-17 12:41:04.073155: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 237s 2s/step - det_loss: 0.1088 - cls_loss: 0.0901 - box_loss: 3.7488e-04 - reg_l2_loss: 0.0633 - loss: 0.1722 - learning_rate: 9.8784e-04 - gradient_norm: 1.6665 - val_det_loss: 0.0987 - val_cls_loss: 0.0821 - val_box_loss: 3.3232e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1620\n",
            "Epoch 22/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1187 - cls_loss: 0.0984 - box_loss: 4.0475e-04 - reg_l2_loss: 0.0633 - loss: 0.1820 - learning_rate: 7.8258e-04 - gradient_norm: 2.22992024-07-17 12:44:44.571211: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 216s 2s/step - det_loss: 0.1183 - cls_loss: 0.0982 - box_loss: 4.0332e-04 - reg_l2_loss: 0.0633 - loss: 0.1817 - learning_rate: 7.8163e-04 - gradient_norm: 2.2177 - val_det_loss: 0.0978 - val_cls_loss: 0.0808 - val_box_loss: 3.4057e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1611\n",
            "Epoch 23/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1021 - cls_loss: 0.0843 - box_loss: 3.5616e-04 - reg_l2_loss: 0.0633 - loss: 0.1655 - learning_rate: 5.9641e-04 - gradient_norm: 1.60202024-07-17 12:48:26.520213: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 224s 2s/step - det_loss: 0.1020 - cls_loss: 0.0842 - box_loss: 3.5502e-04 - reg_l2_loss: 0.0633 - loss: 0.1653 - learning_rate: 5.9556e-04 - gradient_norm: 1.5973 - val_det_loss: 0.0962 - val_cls_loss: 0.0800 - val_box_loss: 3.2460e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1596\n",
            "Epoch 24/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1044 - cls_loss: 0.0839 - box_loss: 4.1183e-04 - reg_l2_loss: 0.0633 - loss: 0.1678 - learning_rate: 4.3256e-04 - gradient_norm: 1.47362024-07-17 12:52:16.620567: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 230s 2s/step - det_loss: 0.1040 - cls_loss: 0.0835 - box_loss: 4.0968e-04 - reg_l2_loss: 0.0633 - loss: 0.1673 - learning_rate: 4.3182e-04 - gradient_norm: 1.4679 - val_det_loss: 0.0969 - val_cls_loss: 0.0804 - val_box_loss: 3.2909e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1602\n",
            "Epoch 25/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1102 - cls_loss: 0.0912 - box_loss: 3.8054e-04 - reg_l2_loss: 0.0633 - loss: 0.1735 - learning_rate: 2.9294e-04 - gradient_norm: 1.64812024-07-17 12:56:11.750645: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 248s 3s/step - det_loss: 0.1103 - cls_loss: 0.0911 - box_loss: 3.8335e-04 - reg_l2_loss: 0.0633 - loss: 0.1736 - learning_rate: 2.9233e-04 - gradient_norm: 1.6445 - val_det_loss: 0.1042 - val_cls_loss: 0.0881 - val_box_loss: 3.2108e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1675\n",
            "Epoch 26/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1060 - cls_loss: 0.0875 - box_loss: 3.6916e-04 - reg_l2_loss: 0.0633 - loss: 0.1693 - learning_rate: 1.7920e-04 - gradient_norm: 1.57912024-07-17 13:00:26.405601: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 243s 2s/step - det_loss: 0.1062 - cls_loss: 0.0877 - box_loss: 3.6975e-04 - reg_l2_loss: 0.0633 - loss: 0.1695 - learning_rate: 1.7873e-04 - gradient_norm: 1.5816 - val_det_loss: 0.1075 - val_cls_loss: 0.0915 - val_box_loss: 3.1876e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1708\n",
            "Epoch 27/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1068 - cls_loss: 0.0874 - box_loss: 3.8774e-04 - reg_l2_loss: 0.0633 - loss: 0.1701 - learning_rate: 9.2669e-05 - gradient_norm: 1.66242024-07-17 13:04:13.157254: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 227s 2s/step - det_loss: 0.1064 - cls_loss: 0.0871 - box_loss: 3.8568e-04 - reg_l2_loss: 0.0633 - loss: 0.1697 - learning_rate: 9.2332e-05 - gradient_norm: 1.6533 - val_det_loss: 0.1028 - val_cls_loss: 0.0870 - val_box_loss: 3.1625e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1661\n",
            "Epoch 28/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.0979 - cls_loss: 0.0821 - box_loss: 3.1664e-04 - reg_l2_loss: 0.0633 - loss: 0.1612 - learning_rate: 3.4361e-05 - gradient_norm: 1.62392024-07-17 13:08:03.792998: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 229s 2s/step - det_loss: 0.0979 - cls_loss: 0.0821 - box_loss: 3.1610e-04 - reg_l2_loss: 0.0633 - loss: 0.1612 - learning_rate: 3.4167e-05 - gradient_norm: 1.6269 - val_det_loss: 0.1052 - val_cls_loss: 0.0893 - val_box_loss: 3.1770e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1685\n",
            "Epoch 29/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1069 - cls_loss: 0.0866 - box_loss: 4.0712e-04 - reg_l2_loss: 0.0633 - loss: 0.1702 - learning_rate: 4.9612e-06 - gradient_norm: 1.69562024-07-17 13:11:58.959677: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 236s 2s/step - det_loss: 0.1069 - cls_loss: 0.0866 - box_loss: 4.0675e-04 - reg_l2_loss: 0.0633 - loss: 0.1703 - learning_rate: 4.9116e-06 - gradient_norm: 1.6935 - val_det_loss: 0.1074 - val_cls_loss: 0.0914 - val_box_loss: 3.1877e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1707\n",
            "Epoch 30/30\n",
            "99/99 [==============================] - ETA: 0s - det_loss: 0.1026 - cls_loss: 0.0846 - box_loss: 3.5982e-04 - reg_l2_loss: 0.0633 - loss: 0.1659 - learning_rate: 4.8132e-06 - gradient_norm: 1.56092024-07-17 13:15:44.820664: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "99/99 [==============================] - 238s 2s/step - det_loss: 0.1032 - cls_loss: 0.0850 - box_loss: 3.6501e-04 - reg_l2_loss: 0.0633 - loss: 0.1665 - learning_rate: 4.9087e-06 - gradient_norm: 1.5615 - val_det_loss: 0.1063 - val_cls_loss: 0.0904 - val_box_loss: 3.1764e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1696\n",
            "2024-07-17 13:17:02.417197: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "2/2 [==============================] - 23s 5s/step\n",
            "\n",
            "2024-07-17 13:17:27.795003: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2024-07-17 13:18:01.468819: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n",
            "2024-07-17 13:18:09.944058: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2024-07-17 13:18:09.944117: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "2024-07-17 13:18:09.950201: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpdyuzjlc9\n",
            "2024-07-17 13:18:10.107944: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2024-07-17 13:18:10.108019: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpdyuzjlc9\n",
            "2024-07-17 13:18:10.653986: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2024-07-17 13:18:13.784005: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpdyuzjlc9\n",
            "2024-07-17 13:18:15.570018: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 5619837 microseconds.\n",
            "2024-07-17 13:18:17.701932: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-07-17 13:18:20.860625: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
            "2024-07-17 13:20:32.461803: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}